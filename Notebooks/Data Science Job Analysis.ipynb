{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f378b651",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-0\"><span class=\"toc-item-num\">0&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Project-Objective\" data-toc-modified-id=\"Project-Objective-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Project Objective</a></span></li><li><span><a href=\"#Dataset-Description\" data-toc-modified-id=\"Dataset-Description-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span>Dataset Description</a></span></li><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-0.3\"><span class=\"toc-item-num\">0.3&nbsp;&nbsp;</span>Imports</a></span></li></ul></li><li><span><a href=\"#Data-Loading-and-Initial-Inspection\" data-toc-modified-id=\"Data-Loading-and-Initial-Inspection-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data Loading and Initial Inspection</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading-The-Dataset\" data-toc-modified-id=\"Loading-The-Dataset-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Loading The Dataset</a></span></li><li><span><a href=\"#Basic-Information-about-the-Dataset\" data-toc-modified-id=\"Basic-Information-about-the-Dataset-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Basic Information about the Dataset</a></span></li><li><span><a href=\"#Summary-Statistics\" data-toc-modified-id=\"Summary-Statistics-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Summary Statistics</a></span></li></ul></li><li><span><a href=\"#Data-Cleaning-and-Preprocessing\" data-toc-modified-id=\"Data-Cleaning-and-Preprocessing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Cleaning and Preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Handling-Missing-Values\" data-toc-modified-id=\"Handling-Missing-Values-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Handling Missing Values</a></span></li><li><span><a href=\"#Data-Type-Conversion\" data-toc-modified-id=\"Data-Type-Conversion-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Data Type Conversion</a></span></li><li><span><a href=\"#Text-Data-Cleaning\" data-toc-modified-id=\"Text-Data-Cleaning-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Text Data Cleaning</a></span></li><li><span><a href=\"#Extraction-of-Additional-Features\" data-toc-modified-id=\"Extraction-of-Additional-Features-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Extraction of Additional Features</a></span><ul class=\"toc-item\"><li><span><a href=\"#Extracting-Hard-and-Soft-Skills-from-Descriptions\" data-toc-modified-id=\"Extracting-Hard-and-Soft-Skills-from-Descriptions-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Extracting Hard and Soft Skills from Descriptions</a></span></li></ul></li><li><span><a href=\"#Job-Requirement-Parsing\" data-toc-modified-id=\"Job-Requirement-Parsing-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Job Requirement Parsing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Extraction-of-Education-Requirements\" data-toc-modified-id=\"Extraction-of-Education-Requirements-2.5.1\"><span class=\"toc-item-num\">2.5.1&nbsp;&nbsp;</span>Extraction of Education Requirements</a></span></li><li><span><a href=\"#Extraction-of-Experience-Requirements\" data-toc-modified-id=\"Extraction-of-Experience-Requirements-2.5.2\"><span class=\"toc-item-num\">2.5.2&nbsp;&nbsp;</span>Extraction of Experience Requirements</a></span></li></ul></li></ul></li><li><span><a href=\"#Exploratory-Data-Analysis\" data-toc-modified-id=\"Exploratory-Data-Analysis-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Exploratory Data Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Distribution-of-Hard-Skills\" data-toc-modified-id=\"Distribution-of-Hard-Skills-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Distribution of Hard Skills</a></span></li><li><span><a href=\"#Distribution-of-Soft-Skills\" data-toc-modified-id=\"Distribution-of-Soft-Skills-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Distribution of Soft Skills</a></span></li><li><span><a href=\"#Distribution-of-Job-Titles\" data-toc-modified-id=\"Distribution-of-Job-Titles-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Distribution of Job Titles</a></span></li><li><span><a href=\"#Distribution-of-Companies\" data-toc-modified-id=\"Distribution-of-Companies-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Distribution of Companies</a></span></li><li><span><a href=\"#Distribution-of-Locations\" data-toc-modified-id=\"Distribution-of-Locations-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Distribution of Locations</a></span></li><li><span><a href=\"#Distribution-of-'Via'\" data-toc-modified-id=\"Distribution-of-'Via'-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Distribution of 'Via'</a></span></li><li><span><a href=\"#Distribution-of-Education\" data-toc-modified-id=\"Distribution-of-Education-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>Distribution of Education</a></span></li><li><span><a href=\"#Distribution-of-Experience\" data-toc-modified-id=\"Distribution-of-Experience-3.8\"><span class=\"toc-item-num\">3.8&nbsp;&nbsp;</span>Distribution of Experience</a></span></li></ul></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Clustering\" data-toc-modified-id=\"Clustering-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Clustering</a></span></li></ul></li><li><span><a href=\"#Model-Selection\" data-toc-modified-id=\"Model-Selection-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Model Selection</a></span><ul class=\"toc-item\"><li><span><a href=\"#Hyperparameter-Tuning\" data-toc-modified-id=\"Hyperparameter-Tuning-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Hyperparameter Tuning</a></span></li><li><span><a href=\"#Model-Training\" data-toc-modified-id=\"Model-Training-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Model Training</a></span></li><li><span><a href=\"#Cluster-Evaluation\" data-toc-modified-id=\"Cluster-Evaluation-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Cluster Evaluation</a></span></li></ul></li><li><span><a href=\"#Insights-from-Clustering\" data-toc-modified-id=\"Insights-from-Clustering-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Insights from Clustering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Visualizing-Clusters\" data-toc-modified-id=\"Visualizing-Clusters-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Visualizing Clusters</a></span></li><li><span><a href=\"#Analyzing-Keywords-for-Each-Cluster\" data-toc-modified-id=\"Analyzing-Keywords-for-Each-Cluster-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Analyzing Keywords for Each Cluster</a></span></li><li><span><a href=\"#Analysis-of-Education-and-Experience-Requirements-by-Job-Title-or-Cluster\" data-toc-modified-id=\"Analysis-of-Education-and-Experience-Requirements-by-Job-Title-or-Cluster-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Analysis of Education and Experience Requirements by Job Title or Cluster</a></span></li></ul></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Conclusion</a></span><ul class=\"toc-item\"><li><span><a href=\"#Summary-of-Findings\" data-toc-modified-id=\"Summary-of-Findings-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Summary of Findings</a></span></li><li><span><a href=\"#Discussion-of-Project-Limitations\" data-toc-modified-id=\"Discussion-of-Project-Limitations-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Discussion of Project Limitations</a></span></li><li><span><a href=\"#Suggestions-for-Future-Work\" data-toc-modified-id=\"Suggestions-for-Future-Work-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Suggestions for Future Work</a></span></li></ul></li><li><span><a href=\"#Appendix\" data-toc-modified-id=\"Appendix-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Appendix</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b94f9e",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eee0af1",
   "metadata": {},
   "source": [
    "The job market is dynamic and not uniform. Skills and qualifications that were in high demand a few years ago might have been replaced by new requirements. Some skills are specific to a single job, while others are transferable, providing value across a variety of roles.\n",
    "\n",
    "For job seekers, understanding the landscape of the job market can be challenging but is essential for making informed career decisions. To address this need, this project aims to shed light on the complexities of the job market by providing a comprehensive analysis based on actual job postings.\n",
    "\n",
    "We will extract and analyze key information from job descriptions across a range of roles, focusing on identifying the most commonly required hard skills, soft skills, educational qualifications, and work experience. The goal is to provide job seekers with an accurate, data-driven understanding of what employers are currently seeking, thereby equipping them to align their skill set and qualifications with market demands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2ad53d",
   "metadata": {},
   "source": [
    "## Project Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20ccfaa",
   "metadata": {},
   "source": [
    "The goal of this project is to provide a detailed, data-driven overview of the current job market based on the analysis of job descriptions from various roles. Our specific objectives are as follows:\n",
    "\n",
    "1. **Analyze job descriptions**: We will utilize Natural Language Processing (NLP) techniques to analyze job descriptions and extract key information about required skills, qualifications, and experience.\n",
    "\n",
    "2. **Identify common requirements**: By examining a variety of job roles, we aim to identify the most common hard and soft skills, educational qualifications, and work experience requirements across these roles.\n",
    "\n",
    "3. **Provide insights for job seekers**: The findings of this analysis will help job seekers understand what skills and qualifications are most in-demand, aiding them in making strategic career decisions.\n",
    "\n",
    "4. **Develop a useful tool**: Ultimately, we aim to present these insights in a user-friendly format, with the long-term goal of developing a web-based tool that can provide real-time analysis to assist job seekers.\n",
    "\n",
    "Through these objectives, we aim to turn the wealth of information present in job postings into actionable insights that can guide job seekers in their career paths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45232aab",
   "metadata": {},
   "source": [
    "## Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b567e9fe",
   "metadata": {},
   "source": [
    "For this project, we will be using multiple datasets containing job postings from different positions. Each dataset will have details of job postings including the job title, company name, location, job description, and more.\n",
    "\n",
    "After loading these datasets, we will merge them into a single dataset for further analysis.\n",
    "\n",
    "The process of cleaning, preprocessing, and merging these datasets will be discussed in detail in the accompanying notebook.\n",
    "\n",
    "The resulting dataset will form the basis for our subsequent analysis, with a focus on the job descriptions. Through these descriptions, we aim to extract key information about the hard skills, soft skills, educational qualifications, and work experience requirements for various roles within the field of data science.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd2749c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13817b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509e1f94",
   "metadata": {},
   "source": [
    "# Data Loading and Initial Inspection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9384a3dc",
   "metadata": {},
   "source": [
    "## Loading The Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728cb693",
   "metadata": {},
   "source": [
    "Dataset from https://www.kaggle.com/datasets/lukebarousse/data-analyst-job-postings-google-search/code\n",
    "\n",
    "Dataset was modified in `Dataset Reduction.ipynb`, wherein we dropped the columns of `job_id`, `thumbnail`, and `commute_time` in order to reduce overall dataset file size to avoid hitting GitHub's 100MB file size limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c70cffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/gsearch_jobs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e41e32d",
   "metadata": {},
   "source": [
    "## Basic Information about the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfbcd14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24734, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d0442c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>via</th>\n",
       "      <th>description</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_min</th>\n",
       "      <th>salary_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Robert Half</td>\n",
       "      <td>Oklahoma City, OK</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Description\\n\\nRobert Half is looking for a pr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Apex Health Solutions</td>\n",
       "      <td>United States</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>Data Analyst Summary Apex Health Solutions is ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marketing Data Analyst</td>\n",
       "      <td>Ledger Bennett</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via LinkedIn</td>\n",
       "      <td>At Ledger Bennett, we strive to help our emplo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boolean Search Data Analyst | $54,000-$108,000...</td>\n",
       "      <td>IT Pros</td>\n",
       "      <td>Anywhere</td>\n",
       "      <td>via Indeed</td>\n",
       "      <td>Company Description\\n\\nJoin a world-class data...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Product Data Analyst - Ditch Witch - Now Hiring</td>\n",
       "      <td>The Toro Company</td>\n",
       "      <td>Perry, OK</td>\n",
       "      <td>via Snagajob</td>\n",
       "      <td>Who Are We?    \\n\\nOur plant in West Salem sta...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title           company_name  \\\n",
       "0                                       Data Analyst            Robert Half   \n",
       "1                                       Data Analyst  Apex Health Solutions   \n",
       "2                             Marketing Data Analyst         Ledger Bennett   \n",
       "3  Boolean Search Data Analyst | $54,000-$108,000...                IT Pros   \n",
       "4    Product Data Analyst - Ditch Witch - Now Hiring       The Toro Company   \n",
       "\n",
       "                 location           via  \\\n",
       "0    Oklahoma City, OK     via LinkedIn   \n",
       "1        United States     via LinkedIn   \n",
       "2               Anywhere   via LinkedIn   \n",
       "3               Anywhere     via Indeed   \n",
       "4            Perry, OK     via Snagajob   \n",
       "\n",
       "                                         description salary  salary_min  \\\n",
       "0  Description\\n\\nRobert Half is looking for a pr...    NaN         NaN   \n",
       "1  Data Analyst Summary Apex Health Solutions is ...    NaN         NaN   \n",
       "2  At Ledger Bennett, we strive to help our emplo...    NaN         NaN   \n",
       "3  Company Description\\n\\nJoin a world-class data...    NaN         NaN   \n",
       "4  Who Are We?    \\n\\nOur plant in West Salem sta...    NaN         NaN   \n",
       "\n",
       "   salary_max  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf2f868",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0d73f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary_min</th>\n",
       "      <th>salary_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4347.000000</td>\n",
       "      <td>4347.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33064.881799</td>\n",
       "      <td>46824.467649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>44097.407835</td>\n",
       "      <td>62398.783381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>77000.000000</td>\n",
       "      <td>110175.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>215000.000000</td>\n",
       "      <td>283000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          salary_min     salary_max\n",
       "count    4347.000000    4347.000000\n",
       "mean    33064.881799   46824.467649\n",
       "std     44097.407835   62398.783381\n",
       "min         8.000000      10.000000\n",
       "25%        20.000000      45.000000\n",
       "50%        50.000000      75.000000\n",
       "75%     77000.000000  110175.000000\n",
       "max    215000.000000  283000.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d41d2e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title            object\n",
       "company_name     object\n",
       "location         object\n",
       "via              object\n",
       "description      object\n",
       "salary           object\n",
       "salary_min      float64\n",
       "salary_max      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165ec17b",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2f50b1",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df33eb19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title               0\n",
       "company_name        0\n",
       "location           19\n",
       "via                 0\n",
       "description         0\n",
       "salary          20106\n",
       "salary_min      20387\n",
       "salary_max      20387\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acb8282c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4307"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83f4f123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24734, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9383619a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title            object\n",
       "company_name     object\n",
       "location         object\n",
       "via              object\n",
       "description      object\n",
       "salary           object\n",
       "salary_min      float64\n",
       "salary_max      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01e62d4",
   "metadata": {},
   "source": [
    "Checking how many unique instances there are in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faead81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title: 9594 unique values\n",
      "company_name: 6300 unique values\n",
      "location: 577 unique values\n",
      "via: 468 unique values\n",
      "description: 17585 unique values\n",
      "salary: 1103 unique values\n",
      "salary_min: 337 unique values\n",
      "salary_max: 374 unique values\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(f'{col}: {df[col].nunique()} unique values')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f2f623",
   "metadata": {},
   "source": [
    "Looking into description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7c39e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Description\\n\\nRobert Half is looking for a programmer analyst who combines a real passion for formulating and defining systems scope and objectives with an understanding of software and applications programming and industry requirements. Through research and fact-finding, you'd make recommendations for developing or modifying applications or databases...\\n\\nWhat you get to do every single day\\n• Build and test programming changes for each phase of systems development prior to implementation. Writes test cases and expected results. Reviews results for conformance to requirements. May plan simple tests or a defined subset of a larger system test. May make recommendations for acceptance/rejection if requirements are not all met\\n• Analyzes user requests for systems changes or improvements. Documents functional requirements and assesses cost, feasibility and utility. Develops recommendation as to how, when or whether to proceed with making the changes\\n• Acts as the in-house guide on applications, systems and/or processes to internal clients in identifying and resolving, processing/reporting programming problems. Consultation can take the form of trouble shooting and/or education\\n• Provides ongoing training and assistance for end users and other partner groups for a particular application, system or process\\n• Analyzes processing procedures. Develops recommendations for improvements\\n• Builds and maintains dictionaries for applications and systems support by the analyst\\n• Analyzes and documents issues. Works with other programmers to correct code problems\\n• Assists in the developing communication content for specific system changes being implemented in production\\n\\nRequirements\\n\\nWhat you bring to the role\\n• Previous experience as a project leader for the business portion of developmental applications or major systems improvements\\n• Comprehensive understanding of programming languages\\n• Strong project planning and management tasks, business systems support functions and project costing techniques\\n• Strong oral and written skills\\n• Knowledge of PC and mainframe hardware/software\\n\\nTechnology Doesn't Change the World, People Do.®\\n\\nRobert Half is the world’s first and largest specialized talent solutions firm that connects highly qualified job seekers to opportunities at great companies. We offer contract, temporary and permanent placement solutions for finance and accounting, technology, marketing and creative, legal, and administrative and customer support roles.\\n\\nRobert Half puts you in the best position to succeed by advocating on your behalf and promoting you to employers. We provide access to top jobs, competitive compensation and benefits, and free online training. Stay on top of every opportunity – even on the go.\\n\\nAll applicants applying for U.S. job openings must be legally authorized to work in the United States. Benefits are available to contract/temporary professionals, including medical, vision, dental, and life and disability insurance. Hired contract/temporary professionals are also eligible to enroll in our company 401(k) plan. Visit\\n\\n© 2023 Robert Half. An Equal Opportunity Employer. M/F/Disability/Veterans. By clicking “Apply Now,” you’re agreeing to\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf9cf6e",
   "metadata": {},
   "source": [
    "## Data Type Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8512e8",
   "metadata": {},
   "source": [
    "## Text Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcf74eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Lowercasing\n",
    "df['description'] = df['description'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24f3b0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Removing Punctuation\n",
    "df['description'] = df['description'].str.replace(r'\\W', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a76c9204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Removing Stop Words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if not word in stop_words]\n",
    "    return \" \".join(filtered_text)\n",
    "\n",
    "df['description'] = df['description'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec885e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Counting word frequencies\n",
    "def count_words(text):\n",
    "    word_tokens = word_tokenize(text)\n",
    "    word_freq = Counter(word_tokens)\n",
    "    return word_freq\n",
    "\n",
    "# Apply the function to each description\n",
    "df['word_counts'] = df['description'].apply(count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9762b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty counter\n",
    "total_word_counts = Counter()\n",
    "\n",
    "# Update it with each counter\n",
    "for word_count in df['word_counts']:\n",
    "    total_word_counts.update(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b61078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning `Location`\n",
    "\n",
    "df['location'] = df['location'].str.lower()\n",
    "df['location'] = df['location'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1754e99e",
   "metadata": {},
   "source": [
    "## Extraction of Additional Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b322513e",
   "metadata": {},
   "source": [
    "### Extracting Hard and Soft Skills from Descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e025f4f2",
   "metadata": {},
   "source": [
    "To extract the ***Hard Skills*** and ***Soft Skills*** from the job descriptions, we will take the 2500 most frequent words, and go through them to create lists of the common skills to iterate through in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48a9b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined hard skills\n",
    "hard_skills = [\"analysis\", \"analytics\", \"sql\", \"reporting\", \"tools\", \"development\", \n",
    "               \"technical\", \"science\", \"statistical\", \"excel\", \"visualization\", \n",
    "               \"python\", \"software\", \"engineering\", \"database\", \"modeling\", \n",
    "               \"techniques\", \"mathematics\", \"languages\", \"programming\", \n",
    "               \"cloud\", \"etl\", \"automation\", \"oracle\", \"machine_learning\", \n",
    "               \"data_processing\", \"data_warehouse\", \"administration\", \"powerbi\", \n",
    "               \"coding\", \"software_development\", \"salesforce\", \"architecture\", \n",
    "               \"server\", \"validation\", \"predictive\", \"aws\", \"azure\", \"snowflake\",\n",
    "               \"powerpoint\", \"word\", \"web_development\", \"mapping\", \"scripting\", \"sap\",\n",
    "               \"structured_query_language\", \"ai\", \"intermediate_programming\", \"descriptive_statistics\", \n",
    "               \"storage_solutions\", \"pipelines\", \"pivot_tables\", \"data_auditing\", \n",
    "               \"workflow_design\", \"algorithm_design\", \"logic\", \"troubleshooting\", \n",
    "               \"regression_analysis\", \"data_cleaning\", \"data_profiling\", \"data_visualization\", \n",
    "               \"project_management\", \"querying\", \"statistical_analysis\", \"data_management\",\n",
    "               \"configuration\", \"data_sourcing\", \"electronic_data_interchange\", \"data_extraction\", \n",
    "               \"hadoop\", \"qa_testing\", \"cybersecurity\", \"java\", \"sharepoint\", \"classification\",\n",
    "               \"kpi_analysis\", \"microstrategy\", \"data_warehouse_architecture\", \"javascript\",\n",
    "               \"data_visualization_tools\", \"data_modelling\", \"scrum\", \"xml\", \"data_protocols\", \n",
    "               \"qlikview\", \"calculations\", \"ssrs\", \"ssis\", \"data_lineage\", \"nosql\", \"roadmap_design\", \n",
    "               \"forecasting\", \"epic_systems\", \"reliability_analysis\", \"spreadsheets\", \"hive\", \n",
    "               \"data_reconciliation\", \"data_consultation\", \"data_architecture\", \"dod_data_standards\", \n",
    "               \"data_integrations\", \"validation_procedures\", \"genetic_data_analysis\", \"pandas\", \n",
    "               \"data_standardization\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a719ac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined soft skills\n",
    "soft_skills = [\"teamwork\", \"management\", \"support\", \"communication\", \"leadership\", \n",
    "               \"problem-solving\", \"collaboration\", \"initiative\", \"adaptability\", \n",
    "               \"interpersonal_skills\", \"networking\", \"passion\", \"responsibility\", \n",
    "               \"ability_to_work_under_pressure\", \"conflict_resolution\", \"creativity\", \n",
    "               \"time_management\", \"multitasking\", \"critical_thinking\", \"decision_making\", \n",
    "               \"empathy\", \"negotiation\", \"motivation\", \"presentation\", \"attention_to_detail\", \n",
    "               \"resilience\", \"flexibility\", \"emotional_intelligence\", \"self-motivation\", \n",
    "               \"accountability\", \"reliable\", \"urgency\", \"attitude\", \"ethical_behavior\", \n",
    "               \"resourcefulness\", \"organizational_skills\", \"mentorship\", \"continuous_learning\", \n",
    "               \"strategic_thinking\", \"engaging\", \"client_focused\", \"result_oriented\", \n",
    "               \"analytical_mindset\", \"innovative\", \"adaptability\", \"persuasion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf16d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_skills = list(set(hard_skills))\n",
    "soft_skills = list(set(soft_skills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b37c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting counts of each of the skills defined within the hard_skills and soft_skills lists\n",
    "hard_skill_counts = {skill: df['description'].str.contains(skill).sum() for skill in hard_skills}\n",
    "soft_skill_counts = {skill: df['description'].str.contains(skill).sum() for skill in soft_skills}\n",
    "\n",
    "df_hard_skills = pd.DataFrame(list(hard_skill_counts.items()), columns=['Skill', 'Count']).sort_values('Count', ascending=False)\n",
    "df_soft_skills = pd.DataFrame(list(soft_skill_counts.items()), columns=['Skill', 'Count']).sort_values('Count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b6b044",
   "metadata": {},
   "source": [
    "## Job Requirement Parsing\n",
    "###  Extraction of Education Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ac6193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_education(description):\n",
    "    if \"phd\" in description.lower():\n",
    "        return \"PhD\"\n",
    "    elif \"master's\" in description.lower() or \"masters\" in description.lower():\n",
    "        return \"Masters\"\n",
    "    elif \"undergrad\" in description.lower() or \"bachelor's\" in description.lower() or \"bsc\" in description.lower() or \"ba\" in description.lower():\n",
    "        return \"Undergrad\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df['education'] = df['description'].apply(extract_education)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f87aab",
   "metadata": {},
   "source": [
    "### Extraction of Experience Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d517e891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_experience(description):\n",
    "    # Regular expression to match patterns like \"2 years\" or \"5+ years\"\n",
    "    match = re.search(r'(\\d+\\+? years?) experience', description)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df['experience'] = df['description'].apply(extract_experience)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409d2817",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627f0c1b",
   "metadata": {},
   "source": [
    "In this section, we'll delve deep into our dataset to visualize and comprehend the distributions of:\n",
    "\n",
    "- Soft_Skill and Hard_Skill frequencies.\n",
    "- Common terms used in Job Title and Job Description across different roles.\n",
    "- The distribution of companies in Company.\n",
    "- The geographic distribution of job postings in Location.\n",
    "- The sources of job listings represented by Via."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fde4278",
   "metadata": {},
   "source": [
    "## Distribution of Hard Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17ed169",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Count', y='Skill', data=df_hard_skills.head(20))\n",
    "plt.title('Top 20 Hard Skills')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfd9492",
   "metadata": {},
   "source": [
    "## Distribution of Soft Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68002f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x='Count', y='Skill', data=df_soft_skills.head(20))\n",
    "plt.title('Top 20 Soft Skills')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4a78cc",
   "metadata": {},
   "source": [
    "## Distribution of Job Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75a66d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the frequency of each job title\n",
    "title_counts = df['title'].value_counts()\n",
    "\n",
    "# Create a color list. Use 'g' for green if 'engineer' is in the job title, 'r' for red if 'scientist' is in the title, and 'b' for blue otherwise\n",
    "colors = ['g' if 'engineer' in title.lower() else 'r' if 'scientist' in title.lower() else 'b' for title in title_counts.index[:15]]\n",
    "\n",
    "# Create a bar plot of the top 20 job titles\n",
    "title_counts[:15].plot(kind='bar', color=colors)\n",
    "plt.title('Top 15 Job Titles')\n",
    "plt.xlabel('Job Titles')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a41957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all job titles that do not contain 'analyst'\n",
    "non_analyst_jobs = df[~df['title'].str.lower().str.contains('analyst')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c64a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the frequency of each job title\n",
    "non_analyst_title_counts = non_analyst_jobs['title'].value_counts()\n",
    "\n",
    "# Create a color list. Use 'g' for green if 'engineer' in the job title, 'r' for red if 'scientist' in the job title, and 'b' for blue otherwise\n",
    "colors = ['g' if 'engineer' in title.lower() else 'r' if 'scientist' in title.lower() else 'b' for title in non_analyst_title_counts.index[:15]]\n",
    "\n",
    "# Create a bar plot of the top 20 job titles\n",
    "non_analyst_title_counts[:15].plot(kind='bar', color=colors)\n",
    "plt.title('Top 15 Non-Analyst Job Titles')\n",
    "plt.xlabel('Job Titles')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f1818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty counter\n",
    "non_analyst_word_counts = Counter()\n",
    "\n",
    "# Update it with each counter\n",
    "for word_count in non_analyst_jobs['word_counts']:\n",
    "    non_analyst_word_counts.update(word_count)\n",
    "\n",
    "# Get a list of all words with their frequencies\n",
    "word_frequencies = non_analyst_word_counts.items()\n",
    "\n",
    "# Filter the list to include only the words that occur more than 100 times\n",
    "common_words = [(word, count) for word, count in word_frequencies if count > 100]\n",
    "\n",
    "# Sort the words by their frequency\n",
    "common_words_sorted = sorted(common_words, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Create a DataFrame for easy plotting\n",
    "df_common_words = pd.DataFrame(common_words_sorted, columns=['word', 'count'])\n",
    "\n",
    "# Create a bar plot of the top 20 words\n",
    "df_common_words[:20].plot(x='word', y='count', kind='bar', legend=False, color='b')\n",
    "plt.title('Top 20 Words in Non-Analyst Job Descriptions')\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05cdf4d",
   "metadata": {},
   "source": [
    "## Distribution of Companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553fde0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_companies = df['company_name'].value_counts().head(10)  # Get top 10 companies\n",
    "sns.barplot(x=top_companies.index, y=top_companies.values)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Top 10 Companies Distribution')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a290db74",
   "metadata": {},
   "source": [
    "## Distribution of Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4cd3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_locations = df['location'].value_counts().head(10)  # Get top 10 locations\n",
    "sns.barplot(x=top_locations.index, y=top_locations.values)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Top 10 Locations Distribution')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd055eb8",
   "metadata": {},
   "source": [
    "## Distribution of 'Via'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716a1ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_via = df['via'].value_counts().head(10)  # Get top 10 sources\n",
    "sns.barplot(x=top_via.index, y=top_via.values)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Top 10 Via/Source Distribution')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4808b52",
   "metadata": {},
   "source": [
    "From this visual, we can see that the majority of the data is obtained via Linkedin. With additional postings being from Upwork, Trabajo.org, BeBee, ZipRecruiter, Indeed, and then there is a dropoff and smaller amounts of postings are from other sites.\n",
    "\n",
    "This is notable due to the listings being pulled from Google job listings, so these likely indicate that most job postings occur via these sources compared to more niche job posting websites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc12d3d5",
   "metadata": {},
   "source": [
    "## Distribution of Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9b6e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for analyst, scientist, and engineer jobs\n",
    "analyst_jobs = df[df['title'].str.lower().str.contains('analyst')]\n",
    "scientist_jobs = df[df['title'].str.lower().str.contains('scientist')]\n",
    "engineer_jobs = df[df['title'].str.lower().str.contains('engineer')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6778512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the grid and figure size\n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "# Create a color palette for the education categories\n",
    "unique_education = df['education'].dropna().unique()\n",
    "education_palette = sns.color_palette(\"deep\", n_colors=len(unique_education))\n",
    "edu_color_map = dict(zip(unique_education, education_palette))\n",
    "\n",
    "# Visualization for Analyst Education Requirements\n",
    "plt.subplot(1, 3, 1)  # 1 row, 3 columns, position 1\n",
    "education_counts_analyst = analyst_jobs['education'].value_counts()\n",
    "sns.barplot(x=education_counts_analyst.index, \n",
    "            y=education_counts_analyst.values, \n",
    "            palette=edu_color_map)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Education Requirements for Analyst Jobs')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Education Level')\n",
    "\n",
    "# Visualization for Scientist Education Requirements\n",
    "plt.subplot(1, 3, 2)  # 1 row, 3 columns, position 2\n",
    "education_counts_scientist = scientist_jobs['education'].value_counts()\n",
    "sns.barplot(x=education_counts_scientist.index, \n",
    "            y=education_counts_scientist.values,\n",
    "            palette=edu_color_map)  # Use the color map here as well\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Education Requirements for Scientist Jobs')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Education Level')\n",
    "\n",
    "# Visualization for Engineer Education Requirements\n",
    "plt.subplot(1, 3, 3)  # 1 row, 3 columns, position 3\n",
    "education_counts_engineer = engineer_jobs['education'].value_counts()\n",
    "sns.barplot(x=education_counts_engineer.index, \n",
    "            y=education_counts_engineer.values, \n",
    "            palette=edu_color_map)  # Use the color map here as well\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Education Requirements for Engineer Jobs')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Education Level')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe15406c",
   "metadata": {},
   "source": [
    "## Distribution of Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dfa310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the grid and figure size\n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "# Create a color palette for the experience categories\n",
    "unique_experience = df['experience'].dropna().unique()\n",
    "experience_palette = sns.color_palette(\"deep\", n_colors=len(unique_experience))\n",
    "exp_color_map = dict(zip(unique_experience, experience_palette))\n",
    "\n",
    "# Visualization for Analyst Experience Requirements\n",
    "plt.subplot(1, 3, 1)  # 1 row, 3 columns, position 1\n",
    "experience_counts_analyst = analyst_jobs['experience'].value_counts().head(10)\n",
    "sns.barplot(x=experience_counts_analyst.index, \n",
    "            y=experience_counts_analyst.values, \n",
    "            palette=exp_color_map)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Experience Requirements for Data Analyst Jobs')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Experience')\n",
    "\n",
    "# Visualization for Scientist Experience Requirements\n",
    "plt.subplot(1, 3, 2)  # 1 row, 3 columns, position 2\n",
    "experience_counts_scientist = scientist_jobs['experience'].value_counts().head(10)\n",
    "sns.barplot(x=experience_counts_scientist.index,  # Use scientist counts here\n",
    "            y=experience_counts_scientist.values,  # Use scientist counts here\n",
    "            palette=exp_color_map)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Experience Requirements for Data Scientist Jobs')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Experience')\n",
    "\n",
    "# Visualization for Engineer Experience Requirements\n",
    "plt.subplot(1, 3, 3)  # 1 row, 3 columns, position 3\n",
    "experience_counts_engineer = engineer_jobs['experience'].value_counts().head(10)\n",
    "sns.barplot(x=experience_counts_engineer.index,  # Use engineer counts here\n",
    "            y=experience_counts_engineer.values,  # Use engineer counts here\n",
    "            palette=exp_color_map)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Experience Requirements for Data Engineer Jobs')\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Experience')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0006fdd4",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960cdb87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0ac798",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4171ae",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d29800c",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa2d612",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da374b4",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2571e4d6",
   "metadata": {},
   "source": [
    "## Cluster Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab16cd0",
   "metadata": {},
   "source": [
    "# Insights from Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d0081e",
   "metadata": {},
   "source": [
    "## Visualizing Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5902ea3",
   "metadata": {},
   "source": [
    "## Analyzing Keywords for Each Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8e5575",
   "metadata": {},
   "source": [
    "## Analysis of Education and Experience Requirements by Job Title or Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3cff41",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d83b2d",
   "metadata": {},
   "source": [
    "## Summary of Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8debd735",
   "metadata": {},
   "source": [
    "## Discussion of Project Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd9c7f5",
   "metadata": {},
   "source": [
    "## Suggestions for Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757d5361",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "466.25px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
